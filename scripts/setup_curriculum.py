#!/usr/bin/env python3
"""
AI í•™ìŠµ ì»¤ë¦¬í˜ëŸ¼ (365ê°œ í‚¤ì›Œë“œ) ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
ì˜¤ëŠ˜ AI í¬ìŠ¤íŒ… ì™„ë£Œ, ë‚´ì¼ë¶€í„° ë‘ ë²ˆì§¸ í‚¤ì›Œë“œë¶€í„° 1ë…„ ë™ì•ˆ ìë™ í¬ìŠ¤íŒ…
"""

#!/usr/bin/env python3
import sys
import os
from pathlib import Path

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from src.core.config import load_env_file
load_env_file()

# ëª¨ë“ˆ import
from src.core.database import Database

# ì»¤ë¦¬í˜ëŸ¼ ë°ì´í„°
CURRICULUM = {
    "â­ AI ê¸°ì´ˆ(1~30)": [
        "ì¸ê³µì§€ëŠ¥(AI)", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹", "ë°ì´í„°", "ëª¨ë¸(Model)", "ì•Œê³ ë¦¬ì¦˜",
        "í›ˆë ¨(Training)", "í…ŒìŠ¤íŠ¸(Test)", "ê²€ì¦(Validation)", "ì˜¤ë²„í”¼íŒ…", "ì–¸ë”í”¼íŒ…",
        "ì¼ë°˜í™”", "í”¼ì²˜(Feature)", "ë¼ë²¨(Label)", "ë°ì´í„°ì…‹", "ìƒ˜í”Œ", "í¸í–¥(Bias)",
        "ë¶„ì‚°(Variance)", "í•˜ì´í¼íŒŒë¼ë¯¸í„°", "ì†ì‹¤í•¨ìˆ˜", "ì •í™•ë„", "ì •ë°€ë„", "ì¬í˜„ìœ¨",
        "F1 ìŠ¤ì½”ì–´", "í˜¼ë™í–‰ë ¬", "íŒŒë¼ë¯¸í„°", "ì—í­(Epoch)", "ë°°ì¹˜(Batch)", "í™•ë¥ ", "í†µê³„ì  ì¶”ì •"
    ],
    "â­ ë¨¸ì‹ ëŸ¬ë‹(31~80)": [
        "ì§€ë„í•™ìŠµ", "ë¹„ì§€ë„í•™ìŠµ", "ê°•í™”í•™ìŠµ", "íšŒê·€", "ë¶„ë¥˜", "ì˜ì‚¬ê²°ì •ë‚˜ë¬´",
        "ëœë¤í¬ë ˆìŠ¤íŠ¸", "ë¶€ìŠ¤íŒ…", "ê·¸ë¼ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…", "XGBoost", "SVM", "KNN",
        "k-means", "PCA", "ì°¨ì› ì¶•ì†Œ", "êµ°ì§‘í™”", "ì´ìƒì¹˜ íƒì§€", "ì—”íŠ¸ë¡œí”¼", "ì§€ë‹ˆê³„ìˆ˜",
        "í•™ìŠµë¥ ", "êµì°¨ê²€ì¦", "ê·¸ë¦¬ë“œì„œì¹˜", "ëª¨ë¸ í‰ê°€", "í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§", "í‘œì¤€í™”",
        "ì •ê·œí™”", "ì›-í•« ì¸ì½”ë”©", "Binning", "ìƒ˜í”Œë§", "ì–¸ë”ìƒ˜í”Œë§", "ì˜¤ë²„ìƒ˜í”Œë§",
        "SMOTE", "ì„ í˜•íšŒê·€", "ë¡œì§€ìŠ¤í‹±íšŒê·€", "ROC ì»¤ë¸Œ", "AUC", "ì„±ëŠ¥ ì§€í‘œ",
        "ì—°ê´€ ê·œì¹™", "Apriori", "ì‹œê°„ ì‹œë¦¬ì¦ˆ", "ì˜ˆì¸¡ ëª¨ë¸", "ì´ë™í‰ê· ", "ARIMA",
        "ë¦¬ìŠ¤í¬ ëª¨ë¸ë§", "ëª¨ë¸ í•´ì„ì„±", "SHAP", "LIME", "í”¼ì²˜ ì¤‘ìš”ë„", "ëª¨ë¸ ë“œë¦¬í”„íŠ¸", "MLOps"
    ],
    "â­ ë”¥ëŸ¬ë‹ ê¸°ì´ˆ(81~140)": [
        "ë‰´ëŸ°", "í¼ì…‰íŠ¸ë¡ ", "í™œì„±í™” í•¨ìˆ˜", "ReLU", "Sigmoid", "Softmax",
        "ì‹ ê²½ë§(NN)", "ë”¥ ë‰´ëŸ´ ë„¤íŠ¸ì›Œí¬(DNN)", "ìˆœì „íŒŒ", "ì—­ì „íŒŒ", "ì†ì‹¤ ê°ì†Œ",
        "ê²½ì‚¬í•˜ê°•ë²•", "ìµœì í™” ì•Œê³ ë¦¬ì¦˜", "Adam", "SGD", "ë°°ì¹˜ ì •ê·œí™”", "ë“œë¡­ì•„ì›ƒ",
        "Convolution", "CNN", "Max pooling", "Feature map", "í•„í„°", "íŒŒë¼ë¯¸í„° ê³µìœ ",
        "ì´ë¯¸ì§€ ë¶„ë¥˜", "Object Detection", "YOLO", "R-CNN", "ResNet", "Skip connection",
        "VGG", "ì „ì´í•™ìŠµ", "Fine-tuning", "ë°ì´í„° ì¦ê°•", "Flatten", "Fully Connected Layer",
        "Autoencoder", "VAE", "GAN", "Generator", "Discriminator", "Latent space",
        "Attention", "Encoder", "Decoder", "Transformer", "Self-attention",
        "Positional encoding", "Multi-head attention", "Layer normalization", "BERT",
        "GPT", "Embedding", "Token", "í† í¬ë‚˜ì´ì €", "Masked Language Model",
        "Next Token Prediction", "RNN", "LSTM", "GRU", "Seq2Seq"
    ],
    "â­ ìì—°ì–´ì²˜ë¦¬ NLP(141~200)": [
        "í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬", "í† í°í™”", "ìŠ¤í†±ì›Œë“œ", "í‘œì œì–´ ì¶”ì¶œ", "í˜•íƒœì†Œ ë¶„ì„",
        "ë‹¨ì–´ ì„ë² ë”©", "Word2Vec", "GloVe", "TF-IDF", "ë¬¸ì¥ ì„ë² ë”©", "Semantic similarity",
        "ì±—ë´‡", "ì§ˆì˜ì‘ë‹µ(QA)", "ìš”ì•½", "ë²ˆì—­ ëª¨ë¸", "ê°ì„± ë¶„ì„",
        "Named Entity Recognition", "ë¬¸ì¥ ë¶„ë¥˜", "ë¬¸ë§¥", "Zero-shot", "Few-shot",
        "Prompt", "Prompt tuning", "Instruction tuning", "Alignment", "RLHF",
        "ì•ˆì „ì„±", "í¸í–¥ ì œê±°", "í† í° ì œí•œ", "ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´", "RAG", "Vector DB",
        "ì„ë² ë”© ê²€ìƒ‰", "LLM íŒŒì¸íŠœë‹", "LoRA", "Quantization", "í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰",
        "ì˜¨í†¨ë¡œì§€", "ì§€ì‹ ê·¸ë˜í”„", "ìì—°ì–´ ìƒì„±(NLG)", "ë¬¸ì¥ ì¬êµ¬ì„±", "ë¬¸ë§¥ì  ì˜ë¯¸",
        "í”„ë¡¬í”„íŠ¸ íŒ¨í„´", "ì²´ì¸ ì˜¤ë¸Œ ì˜íŠ¸", "ì†Œí¬ë˜í‹± í”„ë¡¬í”„íŠ¸", "Tool use", "Function calling",
        "ë©€í‹°ëª¨ë‹¬ ëª¨ë¸", "ì‹œê°-Language ëª¨ë¸(VLM)", "TTS", "STT", "ë¬¸ì¥ í† í° í™•ë¥ ",
        "hallucination", "grounding", "ë°ì´í„° ì •í•©ì„±", "ë¬¸ì¥ êµ¬ì¡°", "ì˜ë¯¸ ë„¤íŠ¸ì›Œí¬",
        "ë¬¸ì„œ ì„ë² ë”©", "Retrieval", "ë¬¸ì„œ ìš”ì•½"
    ],
    "â­ ë°ì´í„°/ì—”ì§€ë‹ˆì–´ë§(201~260)": [
        "ë°ì´í„° íŒŒì´í”„ë¼ì¸", "ETL", "ë°ì´í„° ì „ì²˜ë¦¬", "ì •ì œ(cleaning)", "ì´ìƒì¹˜ ì²˜ë¦¬",
        "ê²°ì¸¡ì¹˜ ì²˜ë¦¬", "ë°ì´í„° í’ˆì§ˆ", "ë¡œê·¸ ë°ì´í„°", "ìŠ¤íŠ¸ë¦¬ë° ë°ì´í„°", "ë¹…ë°ì´í„°",
        "Hadoop", "Spark", "ë°ì´í„° ì›¨ì–´í•˜ìš°ìŠ¤", "ë°ì´í„° ë ˆì´í¬", "íŒŒì¼€(parquet)",
        "ì¸ë±ìŠ¤", "SQL", "NoSQL", "Redis", "ìºì‹±", "API", "API í˜¸ì¶œ", "JSON", "CSV",
        "ìŠ¤í‚¤ë§ˆ", "ë°ì´í„° ì¹´íƒˆë¡œê·¸", "ë²„ì „ ê´€ë¦¬", "Git", "GitHub", "CI/CD",
        "íŒŒì´í”„ë¼ì¸ ìë™í™”", "Docker", "ì»¨í…Œì´ë„ˆ", "Kubernetes", "ë°°í¬", "ì¶”ë¡  ì„œë²„",
        "ì„œë²„ë¦¬ìŠ¤", "GPU", "TPU", "ì—°ì‚° ìµœì í™”", "ë©”ëª¨ë¦¬ ê´€ë¦¬", "ì§€ì—°ì‹œê°„ latency",
        "Throughput", "Scale-out", "Scale-up", "ë¡œë“œë°¸ëŸ°ì‹±", "ìºì‹œ ë¯¸ìŠ¤", "ëª¨ë¸ ì„œë¹™",
        "A/B í…ŒìŠ¤íŠ¸", "Canary ë°°í¬", "ëª¨ë¸ ëª¨ë‹ˆí„°ë§", "ë°ì´í„° ë“œë¦¬í”„íŠ¸", "ë¡œê·¸ ë¶„ì„",
        "ë°±ì—”ë“œ", "í”„ë¡ íŠ¸ì—”ë“œ", "REST API", "GraphQL", "Node.js", "Python", "Streamlit"
    ],
    "â­ ë¹„ì¦ˆë‹ˆìŠ¤ & ì‘ìš© AI(261~330)": [
        "AI ì „ëµ", "AI ROI", "AI ë„ì… ì ˆì°¨", "AI ìœ¤ë¦¬", "ê°œì¸ì •ë³´ ë³´í˜¸",
        "ë°ì´í„° ë³´ì•ˆ", "AI ë¦¬ìŠ¤í¬ ê´€ë¦¬", "ìë™í™”", "RPA", "ì±—ë´‡ ìë™í™”",
        "ë¬¸ì„œ ìë™í™”", "ì—…ë¬´ í”„ë¡œì„¸ìŠ¤ ë¶„ì„", "ì›Œí¬í”Œë¡œìš°", "ì§€ì‹ ê´€ë¦¬", "ë””ì§€í„¸ íŠ¸ìœˆ",
        "ì˜ˆì¸¡ ìœ ì§€ë³´ìˆ˜", "ì‚°ì—…ìš© AI", "ì˜ë£Œ AI", "ê¸ˆìœµ AI", "ë¦¬ìŠ¤í¬ ìŠ¤ì½”ì–´ë§",
        "ì¶”ì²œ ì‹œìŠ¤í…œ", "í•„í„°ë§", "í˜‘ì—… í•„í„°ë§", "ì½˜í…ì¸  ê¸°ë°˜ ì¶”ì²œ", "ê°œì¸í™”",
        "ê³ ê° ì„¸ê·¸ë¨¼íŠ¸", "ë°ì´í„° ê¸°ë°˜ ë§ˆì¼€íŒ…", "A/B ì‹¤í—˜", "CRM", "ê´‘ê³  íƒ€ê²ŒíŒ…",
        "ì„œì¹˜ ì—”ì§„", "SEO", "ëŒ€ê·œëª¨ ë°ì´í„° ì²˜ë¦¬", "Fraud detection", "Price optimization",
        "ìˆ˜ìš” ì˜ˆì¸¡", "ê³µê¸‰ë§ ìµœì í™”", "ë¬¼ë¥˜ ìµœì í™”", "AI ì œí’ˆ ê¸°íš", "PMF", "UX",
        "ì‚¬ìš©ì ì—°êµ¬", "AI í™œìš©ë„ ë¶„ì„", "KPI ì„¤ì •", "AI í”Œë«í¼", "LLMOps", "AI Product",
        "Agent", "Multi-agent system", "Tool agent", "Planning", "Reasoning",
        "Chain-of-thought", "Self-reflection", "Debate", "Memory", "Agent í‰ê°€",
        "Agent ìë™í™”", "AI ì»´íŒ¨ë‹ˆì–¸", "AI ì½”ì¹˜", "AI íŠœí„°", "ìƒì‚°ì„± í–¥ìƒ",
        "ì—…ë¬´ ìë™í™” í”„ë¡¬í”„íŠ¸", "ë°ì´í„° í™œìš© ì „ëµ", "ì‚¬ìš©ì íë¦„", "AI ê¸°ë°˜ ë¶„ì„",
        "ì¸ì‚¬ì´íŠ¸ ë„ì¶œ", "ì‹¤í—˜ ì„¤ê³„", "AI ìœ¤ë¦¬ ê°€ì´ë“œ", "AI ì±…ì„ì„±"
    ],
    "â­ ê³ ê¸‰ ê°œë… & ë¯¸ë˜ ê¸°ìˆ (331~365)": [
        "ì´ˆê±°ëŒ€ ëª¨ë¸", "Scaling law", "Sparse attention", "Mixture-of-Experts",
        "Distillation", "Alignment", "ì˜¤í”ˆì›¨ì´íŠ¸ ëª¨ë¸", "í”„ë¼ì´ë²„ì‹œ ê°•í™” í•™ìŠµ",
        "ì°¨ë“± í”„ë¼ì´ë²„ì‹œ", "ê²½ëŸ‰í™” ëª¨ë¸", "ì§€ì‹ ì¦ë¥˜", "AutoML",
        "Neural Architecture Search", "ì‹ ê²½ë§ ì••ì¶•", "Edge AI", "ì˜¨ë””ë°”ì´ìŠ¤ AI",
        "ë©€í‹°ëª¨ë‹¬ ì¶”ë¡ ", "World model", "Self-supervised learning",
        "Contrastive learning", "ë¶„ì‚° AI", "í˜‘ì—… AI", "ì‹œë®¬ë ˆì´ì…˜ í•™ìŠµ",
        "ë¹„ì„ í˜•ì„±", "ë¶ˆí™•ì‹¤ì„± ì •ëŸ‰í™”", "ë² ì´ì§€ì•ˆ ì¶”ë¡ ", "ì˜ì‚¬ê²°ì • ëª¨ë¸",
        "Explainable AI", "Responsible AI", "AGI", "AI ì•ˆì „ ì—°êµ¬",
        "íœ´ë¨¼ ì¸ ë” ë£¨í”„", "ëª¨ë¸ ê°ì‹œ", "ì‹ ë¢°ì„±", "AIì˜ ë¯¸ë˜"
    ]
}

# ì¹´í…Œê³ ë¦¬ ë§¤í•‘
CATEGORY_MAP = {
    "â­ AI ê¸°ì´ˆ(1~30)": "IT/ì»´í“¨í„°",
    "â­ ë¨¸ì‹ ëŸ¬ë‹(31~80)": "IT/ì»´í“¨í„°",
    "â­ ë”¥ëŸ¬ë‹ ê¸°ì´ˆ(81~140)": "IT/ì»´í“¨í„°",
    "â­ ìì—°ì–´ì²˜ë¦¬ NLP(141~200)": "IT/ì»´í“¨í„°",
    "â­ ë°ì´í„°/ì—”ì§€ë‹ˆì–´ë§(201~260)": "IT/ì»´í“¨í„°",
    "â­ ë¹„ì¦ˆë‹ˆìŠ¤ & ì‘ìš© AI(261~330)": "IT/ì»´í“¨í„°",
    "â­ ê³ ê¸‰ ê°œë… & ë¯¸ë˜ ê¸°ìˆ (331~365)": "IT/ì»´í“¨í„°"
}


def setup_curriculum():
    """ì»¤ë¦¬í˜ëŸ¼ì„ ë°ì´í„°ë² ì´ìŠ¤ì— ì¶”ê°€"""
    db = Database()
    
    # ë°ì´í„°ë² ì´ìŠ¤ì— ìˆœì„œ ë²ˆí˜¸ ì»¬ëŸ¼ ì¶”ê°€
    print("ğŸ“ ë°ì´í„°ë² ì´ìŠ¤ êµ¬ì¡° í™•ì¸ ë° ì—…ë°ì´íŠ¸ ì¤‘...")
    conn = db._get_connection()
    cursor = conn.cursor()
    
    try:
        cursor.execute("ALTER TABLE keywords ADD COLUMN sequence_number INTEGER")
        print("  âœ… sequence_number ì»¬ëŸ¼ ì¶”ê°€ë¨")
    except sqlite3.OperationalError:
        print("  â„¹ï¸  sequence_number ì»¬ëŸ¼ ì´ë¯¸ ì¡´ì¬í•¨")
    
    conn.commit()
    conn.close()
    
    # ìˆœì„œëŒ€ë¡œ í‚¤ì›Œë“œ ì¶”ê°€
    all_keywords = []
    sequence = 1
    
    for category_name, keywords in CURRICULUM.items():
        category = CATEGORY_MAP.get(category_name, "IT/ì»´í“¨í„°")
        for keyword in keywords:
            all_keywords.append({
                "keyword": keyword,
                "category": category,
                "sequence": sequence,
                "category_name": category_name
            })
            sequence += 1
    
    print(f"\nğŸ“š ì´ {len(all_keywords)}ê°œì˜ í‚¤ì›Œë“œë¥¼ ë°œê²¬í–ˆìŠµë‹ˆë‹¤.")
    print(f"   (AIëŠ” ì´ë¯¸ í¬ìŠ¤íŒ…ë˜ì—ˆìœ¼ë¯€ë¡œ ì œì™¸)\n")
    
    # ê¸°ì¡´ í‚¤ì›Œë“œ í™•ì¸ (AIëŠ” ì´ë¯¸ ìˆìŒ)
    existing_ai = db.get_keyword_by_name("ì¸ê³µì§€ëŠ¥(AI)")
    if not existing_ai:
        existing_ai = db.get_keyword_by_name("AI")
    
    added_count = 0
    updated_count = 0
    skipped_count = 0
    
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print("ğŸ”§ í‚¤ì›Œë“œ ì¶”ê°€ ì¤‘...")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
    
    for kw_data in all_keywords:
        keyword = kw_data["keyword"]
        category = kw_data["category"]
        sequence = kw_data["sequence"]
        
        # AIëŠ” ì´ë¯¸ í¬ìŠ¤íŒ…ë˜ì—ˆìœ¼ë¯€ë¡œ sequenceë§Œ ì—…ë°ì´íŠ¸
        if keyword in ["ì¸ê³µì§€ëŠ¥(AI)", "AI"]:
            existing = db.get_keyword_by_name(keyword)
            if existing:
                # sequence_number ì—…ë°ì´íŠ¸
                conn = db._get_connection()
                cursor = conn.cursor()
                cursor.execute(
                    "UPDATE keywords SET sequence_number = ? WHERE id = ?",
                    (sequence, existing['id'])
                )
                conn.commit()
                conn.close()
                print(f"  âœ… [{sequence:3d}] {keyword} (ê¸°ì¡´ í‚¤ì›Œë“œ, ìˆœì„œ ë²ˆí˜¸ë§Œ ì—…ë°ì´íŠ¸)")
                updated_count += 1
                skipped_count += 1
            continue
        
        # ê¸°ì¡´ í‚¤ì›Œë“œ í™•ì¸
        existing = db.get_keyword_by_name(keyword)
        
        if existing:
            # ê¸°ì¡´ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìˆœì„œ ë²ˆí˜¸ë§Œ ì—…ë°ì´íŠ¸
            conn = db._get_connection()
            cursor = conn.cursor()
            cursor.execute(
                "UPDATE keywords SET sequence_number = ? WHERE id = ?",
                (sequence, existing['id'])
            )
            conn.commit()
            conn.close()
            print(f"  âœ… [{sequence:3d}] {keyword} (ê¸°ì¡´, ìˆœì„œë§Œ ì—…ë°ì´íŠ¸)")
            updated_count += 1
        else:
            # ìƒˆ í‚¤ì›Œë“œ ì¶”ê°€ (ë¹„í™œì„± ìƒíƒœë¡œ)
            keyword_id = db.add_keyword(
                keyword=keyword,
                category=category,
                is_active=False,
                sequence_number=sequence
            )
            
            print(f"  â• [{sequence:3d}] {keyword} (ì¶”ê°€ë¨)")
            added_count += 1
    
    print(f"\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"âœ… ì»¤ë¦¬í˜ëŸ¼ ì„¤ì • ì™„ë£Œ!")
    print(f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print(f"  â• ìƒˆë¡œ ì¶”ê°€: {added_count}ê°œ")
    print(f"  ğŸ”„ ê¸°ì¡´ í‚¤ì›Œë“œ ì—…ë°ì´íŠ¸: {updated_count}ê°œ")
    print(f"  â­ï¸  ê±´ë„ˆëœ€ (AI): {skipped_count}ê°œ")
    print(f"  ğŸ“Š ì´ í‚¤ì›Œë“œ: {len(all_keywords)}ê°œ")
    print(f"\nğŸ’¡ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   1. ë‘ ë²ˆì§¸ í‚¤ì›Œë“œ 'ë¨¸ì‹ ëŸ¬ë‹'ì„ í™œì„±í™”í•©ë‹ˆë‹¤.")
    print(f"   2. ë§¤ì¼ ìë™ìœ¼ë¡œ ë‹¤ìŒ í‚¤ì›Œë“œë¥¼ í™œì„±í™”í•˜ëŠ” ìŠ¤ì¼€ì¤„ëŸ¬ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.")
    print()


def activate_next_keyword():
    """ë‹¤ìŒ ìˆœì„œì˜ í‚¤ì›Œë“œë¥¼ í™œì„±í™” (í˜„ì¬ í™œì„± í‚¤ì›Œë“œ ë¹„í™œì„±í™”)"""
    db = Database()
    
    # í˜„ì¬ í™œì„± í‚¤ì›Œë“œ ì°¾ê¸°
    active_keywords = db.get_active_keywords()
    
    if not active_keywords:
        print("âš ï¸  í™œì„± í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    current_keyword = active_keywords[0]
    current_seq = None
    
    # í˜„ì¬ í‚¤ì›Œë“œì˜ sequence_number í™•ì¸
    conn = db._get_connection()
    cursor = conn.cursor()
    cursor.execute(
        "SELECT sequence_number FROM keywords WHERE id = ?",
        (current_keyword['id'],)
    )
    row = cursor.fetchone()
    if row:
        current_seq = row['sequence_number']
    conn.close()
    
    if current_seq is None:
        print(f"âš ï¸  '{current_keyword['keyword']}' í‚¤ì›Œë“œì— ìˆœì„œ ë²ˆí˜¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None
    
    # ë‹¤ìŒ ìˆœì„œ í‚¤ì›Œë“œ ì°¾ê¸°
    next_seq = current_seq + 1
    conn = db._get_connection()
    cursor = conn.cursor()
    cursor.execute(
        "SELECT id, keyword FROM keywords WHERE sequence_number = ?",
        (next_seq,)
    )
    next_row = cursor.fetchone()
    conn.close()
    
    if not next_row:
        print(f"âœ… ëª¨ë“  í‚¤ì›Œë“œë¥¼ ì™„ë£Œí–ˆìŠµë‹ˆë‹¤! (í˜„ì¬: {current_keyword['keyword']}, ìˆœì„œ: {current_seq})")
        return None
    
    next_keyword_id = next_row['id']
    next_keyword_name = next_row['keyword']
    
    # í˜„ì¬ í‚¤ì›Œë“œ ë¹„í™œì„±í™”
    db.toggle_keyword(current_keyword['keyword'])
    
    # ë‹¤ìŒ í‚¤ì›Œë“œ í™œì„±í™”
    db.toggle_keyword(next_keyword_name)
    
    print(f"ğŸ”„ í‚¤ì›Œë“œ ì „í™˜ ì™„ë£Œ!")
    print(f"   ì´ì „: {current_keyword['keyword']} (ìˆœì„œ: {current_seq})")
    print(f"   ë‹¤ìŒ: {next_keyword_name} (ìˆœì„œ: {next_seq})")
    
    return next_keyword_name


if __name__ == '__main__':
    import sqlite3
    
    if len(sys.argv) > 1 and sys.argv[1] == 'activate_next':
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("ğŸ”„ ë‹¤ìŒ í‚¤ì›Œë“œ í™œì„±í™”")
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
        activate_next_keyword()
    else:
        setup_curriculum()
        
        # ë‘ ë²ˆì§¸ í‚¤ì›Œë“œ í™œì„±í™”
        print("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
        print("ğŸ”„ ë‘ ë²ˆì§¸ í‚¤ì›Œë“œ í™œì„±í™”")
        print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
        
        # AI í‚¤ì›Œë“œ ë¹„í™œì„±í™”í•˜ê³  ë¨¸ì‹ ëŸ¬ë‹ í™œì„±í™”
        db = Database()
        ai_keyword = db.get_keyword_by_name("ì¸ê³µì§€ëŠ¥(AI)")
        if not ai_keyword:
            ai_keyword = db.get_keyword_by_name("AI")
        
        if ai_keyword:
            db.toggle_keyword(ai_keyword['keyword'])  # ë¹„í™œì„±í™”
        
        # ë¨¸ì‹ ëŸ¬ë‹ í™œì„±í™”
        ml_keyword = db.get_keyword_by_name("ë¨¸ì‹ ëŸ¬ë‹")
        if ml_keyword:
            if not ml_keyword['is_active']:
                db.toggle_keyword("ë¨¸ì‹ ëŸ¬ë‹")
            print(f"âœ… '{ml_keyword['keyword']}' í™œì„±í™” ì™„ë£Œ!")
        else:
            print("âš ï¸  'ë¨¸ì‹ ëŸ¬ë‹' í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

