#!/usr/bin/env python3
"""
ìë™ í¬ìŠ¤íŒ… ë©”ì¸ ìŠ¤í¬ë¦½íŠ¸
- í‚¤ì›Œë“œ í•˜ë‚˜ë§Œ ì²˜ë¦¬
- í•œê¸€ 1ê°œ + ì˜ë¬¸ 1ê°œ í¬ìŠ¤íŒ…
- ì¤‘ë³µ ë°©ì§€
- ì¶œì²˜ ë° ë©´ì±…ë¬¸êµ¬ í•„ìˆ˜
"""

import sys
from datetime import datetime
from database import Database
from agents.agent_chain import AgentChain
from agents.keyword_inference_agent import KeywordInferenceAgent
import os


def load_env_file():
    """.env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ"""
    env_path = os.path.join(os.path.dirname(__file__), '.env')
    if os.path.exists(env_path):
        with open(env_path, 'r', encoding='utf-8') as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith('#') and '=' in line:
                    key, value = line.split('=', 1)
                    key = key.strip()
                    value = value.strip().strip('"').strip("'")
                    if key and value:
                        os.environ[key] = value


def ensure_sources_and_disclaimer(content: str) -> str:
    """ì¶œì²˜ì™€ ë©´ì±…ë¬¸êµ¬ê°€ ìˆëŠ”ì§€ í™•ì¸í•˜ê³  ì—†ìœ¼ë©´ ì¶”ê°€"""
    has_sources = "## ì°¸ê³  ì¶œì²˜" in content or "## References" in content
    has_disclaimer = "ë³¸ ê¸€ì˜ ì •ë³´ëŠ” 100%" in content or "information in this article may not be 100%" in content
    
    if not has_sources:
        # ì¶œì²˜ ì„¹ì…˜ ì¶”ê°€ í•„ìš” (ê²½ê³ )
        print("  âš ï¸  ê²½ê³ : ì¶œì²˜ ì„¹ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
    
    if not has_disclaimer:
        # ë©´ì±… ë¬¸êµ¬ ì¶”ê°€
        if "## ì°¸ê³  ì¶œì²˜" in content or "References" in content:
            # ì¶œì²˜ ë‹¤ìŒì— ì¶”ê°€
            if "## References" in content:
                content += "\n\n---\n\n<span style='color: #666; font-size: 0.9em;'>âš ï¸ The information in this article may not be 100% accurate. Please use it as a reference.</span>"
            else:
                content += "\n\n---\n\n<span style='color: #666; font-size: 0.9em;'>âš ï¸ ë³¸ ê¸€ì˜ ì •ë³´ëŠ” 100% ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³  ìë£Œë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.</span>"
        else:
            # ëì— ì¶”ê°€
            if any(keyword in content.lower() for keyword in ['the', 'is', 'are', 'this', 'that']):
                # ì˜ë¬¸ìœ¼ë¡œ íŒë‹¨
                content += "\n\n---\n\n<span style='color: #666; font-size: 0.9em;'>âš ï¸ The information in this article may not be 100% accurate. Please use it as a reference.</span>"
            else:
                # í•œê¸€ë¡œ íŒë‹¨
                content += "\n\n---\n\n<span style='color: #666; font-size: 0.9em;'>âš ï¸ ë³¸ ê¸€ì˜ ì •ë³´ëŠ” 100% ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì°¸ê³  ìë£Œë¡œ í™œìš©í•˜ì‹œê¸° ë°”ëë‹ˆë‹¤.</span>"
    
    return content


def process_single_keyword_dual_language():
    """ë‹¨ì¼ í‚¤ì›Œë“œë¥¼ í•œê¸€/ì˜ë¬¸ ê° 1ê°œì”© í¬ìŠ¤íŒ…"""
    load_env_file()
    
    db = Database()
    
    # ì²« ë²ˆì§¸ í™œì„± í‚¤ì›Œë“œë§Œ ê°€ì ¸ì˜¤ê¸°
    keyword = db.get_first_active_keyword()
    
    if not keyword:
        print("ğŸ“ ì²˜ë¦¬í•  í™œì„± í‚¤ì›Œë“œê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    keyword_id = keyword['id']
    keyword_name = keyword['keyword']
    notion_page_id = keyword.get('notion_page_id') or os.getenv("NOTION_PARENT_PAGE_ID")
    
    print(f"\n{'='*60}")
    print(f"ğŸš€ ìë™ í¬ìŠ¤íŒ… ì‹œì‘: '{keyword_name}'")
    print(f"{'='*60}\n")
    
    # ì˜¤ëŠ˜ ì´ë¯¸ í¬ìŠ¤íŒ…í–ˆëŠ”ì§€ í™•ì¸
    today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)
    last_posted = db.get_keyword_last_posted(keyword_id)
    
    if last_posted and last_posted >= today:
        print(f"â­ï¸  ì˜¤ëŠ˜ ì´ë¯¸ í¬ìŠ¤íŒ…ë˜ì—ˆìŠµë‹ˆë‹¤. ê±´ë„ˆëœë‹ˆë‹¤.")
        return
    
    chain = AgentChain()
    
    # 1. í•œê¸€ í¬ìŠ¤íŒ…
    print(f"\nğŸ“ [1/2] í•œê¸€ í¬ìŠ¤íŒ… ì‹œì‘\n")
    try:
        result_korean = chain.process(keyword_name, notion_page_id, language='korean')
        
        if result_korean["status"] == "success":
            content_korean = result_korean['generated_content']
            
            # ì¶œì²˜ì™€ ë©´ì±…ë¬¸êµ¬ í™•ì¸
            content_korean['content'] = ensure_sources_and_disclaimer(content_korean['content'])
            
            # ì¤‘ë³µ ì²´í¬ í›„ ì €ì¥
            try:
                post_id_korean = db.create_post(
                    keyword_id=keyword_id,
                    title=content_korean['title'],
                    content=content_korean['content'],
                    search_results=[],
                    status='published' if result_korean['posting_info'].get('page_id') else 'draft',
                    language='korean'
                )
                
                # í¬ìŠ¤íŒ… ì„±ê³µ ì‹œ ì—…ë°ì´íŠ¸
                if result_korean['posting_info'].get('page_id'):
                    db.update_post_published(
                        post_id_korean,
                        result_korean['posting_info']['page_id'],
                        result_korean['posting_info'].get('page_url', '')
                    )
                
                print(f"\nâœ… í•œê¸€ í¬ìŠ¤íŒ… ì™„ë£Œ!")
                if result_korean['posting_info'].get('page_url'):
                    print(f"   URL: {result_korean['posting_info']['page_url']}")
            except ValueError as e:
                if "ì¤‘ë³µ" in str(e):
                    print(f"  â­ï¸  ì¤‘ë³µ í¬ìŠ¤íŠ¸: {e}")
                else:
                    raise
        else:
            print(f"  âŒ í•œê¸€ í¬ìŠ¤íŒ… ì‹¤íŒ¨: {result_korean.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
    except Exception as e:
        print(f"  âŒ í•œê¸€ í¬ìŠ¤íŒ… ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    # 2. ì˜ë¬¸ í¬ìŠ¤íŒ…
    print(f"\nğŸ“ [2/2] ì˜ë¬¸ í¬ìŠ¤íŒ… ì‹œì‘\n")
    try:
        result_english = chain.process(keyword_name, notion_page_id, language='english')
        
        if result_english["status"] == "success":
            content_english = result_english['generated_content']
            
            # ì¶œì²˜ì™€ ë©´ì±…ë¬¸êµ¬ í™•ì¸
            content_english['content'] = ensure_sources_and_disclaimer(content_english['content'])
            
            # ì¤‘ë³µ ì²´í¬ í›„ ì €ì¥
            try:
                post_id_english = db.create_post(
                    keyword_id=keyword_id,
                    title=content_english['title'],
                    content=content_english['content'],
                    search_results=[],
                    status='published' if result_english['posting_info'].get('page_id') else 'draft',
                    language='english'
                )
                
                # í¬ìŠ¤íŒ… ì„±ê³µ ì‹œ ì—…ë°ì´íŠ¸
                if result_english['posting_info'].get('page_id'):
                    db.update_post_published(
                        post_id_english,
                        result_english['posting_info']['page_id'],
                        result_english['posting_info'].get('page_url', '')
                    )
                
                print(f"\nâœ… ì˜ë¬¸ í¬ìŠ¤íŒ… ì™„ë£Œ!")
                if result_english['posting_info'].get('page_url'):
                    print(f"   URL: {result_english['posting_info']['page_url']}")
            except ValueError as e:
                if "ì¤‘ë³µ" in str(e):
                    print(f"  â­ï¸  ì¤‘ë³µ í¬ìŠ¤íŠ¸: {e}")
                else:
                    raise
        else:
            print(f"  âŒ ì˜ë¬¸ í¬ìŠ¤íŒ… ì‹¤íŒ¨: {result_english.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
    except Exception as e:
        print(f"  âŒ ì˜ë¬¸ í¬ìŠ¤íŒ… ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    # í‚¤ì›Œë“œ ìƒíƒœ ì—…ë°ì´íŠ¸
    db.update_keyword_last_checked(keyword_id)
    db.update_keyword_last_posted(keyword_id)
    
    # ë‹¤ìŒ í‚¤ì›Œë“œ ìë™ ì¶”ë¡  ë° ì¶”ê°€
    print(f"\n{'='*60}")
    print(f"ğŸ”® ë‹¤ìŒ í‚¤ì›Œë“œ ì¶”ë¡  ì¤‘...")
    print(f"{'='*60}\n")
    
    try:
        inference_agent = KeywordInferenceAgent()
        
        # ì´ì „ í¬ìŠ¤íŒ… ìˆ˜ì§‘
        previous_posts = db.get_recent_posts_for_keyword(keyword_id, limit=5)
        parent_posts = db.get_recent_posts_for_parent_keywords(keyword_id, limit=5)
        all_previous_posts = (previous_posts + parent_posts)[:10]  # ìµœëŒ€ 10ê°œ
        
        # í•™ìŠµ ê²½ë¡œ ê°€ì ¸ì˜¤ê¸°
        learning_path = db.get_keyword_learning_path(keyword_id)
        
        inference_input = {
            "keyword": keyword_name,
            "previous_posts": all_previous_posts,
            "learning_path": learning_path
        }
        
        inference_result = inference_agent.process(inference_input)
        
        if inference_result.get("status") == "success":
            next_keyword = inference_result.get("next_keyword")
            reason = inference_result.get("reason", "")
            learning_level = inference_result.get("learning_level", "intermediate")
            connection = inference_result.get("connection", "")
            
            print(f"  ğŸ’¡ ì¶”ë¡ ëœ ë‹¤ìŒ í‚¤ì›Œë“œ: '{next_keyword}'")
            print(f"     ì´ìœ : {reason}")
            print(f"     ì—°ê²°ê³ ë¦¬: {connection}")
            
            # ë‹¤ìŒ í‚¤ì›Œë“œê°€ ì´ë¯¸ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
            existing_keyword = db.get_keyword_by_name(next_keyword)
            
            if not existing_keyword:
                # ìƒˆ í‚¤ì›Œë“œ ì¶”ê°€
                next_keyword_id = db.add_keyword(
                    keyword=next_keyword,
                    notion_page_id=notion_page_id,
                    parent_keyword_id=keyword_id,  # í˜„ì¬ í‚¤ì›Œë“œë¥¼ ë¶€ëª¨ë¡œ
                    learning_level=learning_level
                )
                print(f"  âœ… ë‹¤ìŒ í‚¤ì›Œë“œ '{next_keyword}' ì¶”ê°€ë¨ (ID: {next_keyword_id})")
                
                # ì™„ì „ ìë™í™”: í˜„ì¬ í‚¤ì›Œë“œ ë¹„í™œì„±í™”, ë‹¤ìŒ í‚¤ì›Œë“œ ìë™ í™œì„±í™”
                auto_activate = os.getenv("AUTO_ACTIVATE_NEXT_KEYWORD", "false").lower() == "true"
                
                if auto_activate:
                    # í˜„ì¬ í‚¤ì›Œë“œ ë¹„í™œì„±í™” (ì˜¤ëŠ˜ í¬ìŠ¤íŒ… ì™„ë£Œí–ˆìœ¼ë¯€ë¡œ)
                    db.toggle_keyword(keyword_name)
                    # ë‹¤ìŒ í‚¤ì›Œë“œ í™œì„±í™”
                    db.toggle_keyword(next_keyword)
                    print(f"  ğŸ”„ ì™„ì „ ìë™í™” ëª¨ë“œ: í˜„ì¬ í‚¤ì›Œë“œ '{keyword_name}' ë¹„í™œì„±í™”, ë‹¤ìŒ í‚¤ì›Œë“œ '{next_keyword}' ìë™ í™œì„±í™”")
                else:
                    print(f"  ğŸ’¡ í˜„ì¬ í‚¤ì›Œë“œ '{keyword_name}'ëŠ” í™œì„±í™” ìƒíƒœë¥¼ ìœ ì§€í•©ë‹ˆë‹¤.")
                    print(f"     ë‹¤ìŒ í‚¤ì›Œë“œ '{next_keyword}'ë¥¼ í™œì„±í™”í•˜ë ¤ë©´:")
                    print(f"     python3 main.py toggle-keyword \"{next_keyword}\"")
                    print(f"     (ì™„ì „ ìë™í™”ë¥¼ ì›í•˜ì‹œë©´ .envì— AUTO_ACTIVATE_NEXT_KEYWORD=true ì¶”ê°€)")
            else:
                print(f"  â„¹ï¸  ë‹¤ìŒ í‚¤ì›Œë“œ '{next_keyword}'ëŠ” ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤.")
                
                # ì™„ì „ ìë™í™”: ê¸°ì¡´ í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ìë™ í™œì„±í™”
                auto_activate = os.getenv("AUTO_ACTIVATE_NEXT_KEYWORD", "false").lower() == "true"
                
                if auto_activate and not existing_keyword.get('is_active'):
                    # í˜„ì¬ í‚¤ì›Œë“œ ë¹„í™œì„±í™”
                    db.toggle_keyword(keyword_name)
                    # ë‹¤ìŒ í‚¤ì›Œë“œ í™œì„±í™”
                    db.toggle_keyword(next_keyword)
                    print(f"  ğŸ”„ ì™„ì „ ìë™í™” ëª¨ë“œ: ê¸°ì¡´ í‚¤ì›Œë“œ '{next_keyword}' ìë™ í™œì„±í™”")
                
        else:
            print(f"  âš ï¸  ë‹¤ìŒ í‚¤ì›Œë“œ ì¶”ë¡  ì‹¤íŒ¨: {inference_result.get('message', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}")
            
    except Exception as e:
        print(f"  âš ï¸  ë‹¤ìŒ í‚¤ì›Œë“œ ì¶”ë¡  ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
    
    print(f"\n{'='*60}")
    print(f"âœ… ìë™ í¬ìŠ¤íŒ… ì™„ë£Œ!")
    print(f"{'='*60}\n")


if __name__ == '__main__':
    process_single_keyword_dual_language()

